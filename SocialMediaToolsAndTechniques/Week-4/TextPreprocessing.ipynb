{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "Before analysing text data, it's essential to preprocess it to ensure consistency and to remove noise. Common preprocessing steps include:\n",
    "\n",
    "1. **Tokenization**: Splitting text into individual words or sentences.\n",
    "\n",
    "2. **Lowercasing**: Converting all characters to lowercase to maintain uniformity.\n",
    "\n",
    "2. **Removing** Punctuation and Special Characters: Eliminating unnecessary symbols that do not contribute to the analysis.\n",
    "\n",
    "2. **Removing** Stopwords: Filtering out common words (e.g., 'and', 'the', 'is') that may not carry significant meaning.\n",
    "\n",
    "2. **Stemming**: Reducing words to their root form (e.g., 'running' to 'run').\n",
    "\n",
    "2. **Lemmatization**: Converting words to their base or dictionary form (e.g., 'better' to 'good').\n",
    "\n",
    "We will be using NLTK library to demonstrate Text Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to NLTK\n",
    "- NLTK (Natural Language Toolkit) is a powerful Python library for Natural Language Processing (NLP) and Computational Linguistics. It  provides a set of tools for text processing, classification, tokenization, stemming, lemmatization, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\shoyeb ansari\\appdata\\roaming\\python\\python312\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\tools\\manim\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\shoyeb ansari\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\shoyeb ansari\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\tools\\manim\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: colorama in c:\\tools\\manim\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# install nltk\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's learn text preprocessing by using the example\n",
    "\n",
    "text =  \"\"\"The voice that navigated was definitely that of a machine, and yet you could tell that the machine was a woman.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenization\n",
    "- Tokenization is the process of splitting text into individual units, such as words or sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The voice that navigated was definitely that of a machine, and yet you could tell that the machine was a woman.']\n"
     ]
    }
   ],
   "source": [
    " \n",
    "from nltk.tokenize import sent_tokenize\n",
    "sentences = sent_tokenize(text, language=\"english\")\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Word Tokenization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'voice', 'that', 'navigated', 'was', 'definitely', 'that', 'of', 'a', 'machine', ',', 'and', 'yet', 'you', 'could', 'tell', 'that', 'the', 'machine', 'was', 'a', 'woman', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stemming\n",
    "- Stemming reduces words to their root form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happi\n",
      "happier\n",
      "happi\n",
      "breath\n"
     ]
    }
   ],
   "source": [
    "# First way\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "words = ['happy', 'happier', 'happiness', 'breathing']\n",
    "\n",
    "for word in words:\n",
    "    print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy --> happi\n",
      "happier --> happier\n",
      "happiness --> happi\n",
      "breathing --> breath\n"
     ]
    }
   ],
   "source": [
    "# Second way - using Snowball Stemmer\n",
    "\n",
    "from  nltk.stem import SnowballStemmer\n",
    "snowBallStemmer = SnowballStemmer(\"english\")\n",
    "for word in words:\n",
    "    print(word, '-->', snowBallStemmer.stem(word))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before ['The', 'voice', 'that', 'navigated', 'was', 'definitely', 'that', 'of', 'a', 'machine', ',', 'and', 'yet', 'you', 'could', 'tell', 'that', 'the', 'machine', 'was', 'a', 'woman', '.']\n",
      "After: ['the', 'voic', 'that', 'navig', 'wa', 'definit', 'that', 'of', 'a', 'machin', ',', 'and', 'yet', 'you', 'could', 'tell', 'that', 'the', 'machin', 'wa', 'a', 'woman', '.']\n"
     ]
    }
   ],
   "source": [
    "# Let's use PorterStemmer\n",
    "print(f\"before {tokens}\")\n",
    "for i in range(0, len(tokens)):\n",
    "    tokens[i] = stemmer.stem(tokens[i])\n",
    "    \n",
    "print(f\"After: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Lemmatization\n",
    "- Lemmatization is similar to stemming but returns meaningful root words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in range(0, len(tokens)):\n",
    "    tokens[i] = tokens[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filtering Stop Words \n",
    "Stop words are common words that do not add much meaning to the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
